{
  "hosts": [
    {
      "name": "LlamaCpp01",
      "url": "{LlamaCpp-api-endpoint-01}",
      "type": "llama.cpp",
      "models": [
        "granite4:350m"
      ],
      "systemprompt": "You are a helpful assistant",
      "parameters": {
        "logProbs": true
      }
    },
    {
      "name": "LlamaCpp02",
      "url": "{LlamaCpp-api-endpoint-02}",
      "type": "llama.cpp",
      "models": [
        "granite3.1-moe:1b"
      ],
      "systemprompt": "You are a helpful assistant",
      "parameters": {
        "logProbs": true
      }
    },
    {
      "name": "LlamaCpp03",
      "url": "{LlamaCpp-api-endpoint-03}",
      "type": "llama.cpp",
      "models": [
        "llama3.2:1b"
      ],
      "systemprompt": "You are a helpful assistant",
      "parameters": {
        "logProbs": true
      }
    }
  ],
  "timeout": 600,
  "debug": true,
  "multimodelMode": false,
  "pipelineMode": false,
  "jsonMode": false,
  "mcpMode": false,
  "benchmarkMode": false,
  "benchmarkCount": 0,
  "accuracyMode": true,
  "mcpBinary": "dist/agon-mcp_linux_amd64_v1/agon-mcp",
  "mcpInitTimeout": 10,
  "mcpRetryCount": 1,
  "export": "",
  "exportMarkdown": "",
  "metrics": true
}

