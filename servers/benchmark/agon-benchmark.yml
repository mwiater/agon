# benchmarks server config
host: 0.0.0.0
port: 9999
type: "llama.cpp" # only "llama.cpp"
api_base: http://192.168.0.33:8888
models_path: C:\Users\matt\projects\gollama\models
timeout: 3600 # seconds
