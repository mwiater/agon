[
  {
    "build_commit": "d1e355648",
    "build_number": 7783,
    "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ",
    "gpu_info": "AMD Radeon(TM) 8060S Graphics",
    "backends": "Vulkan",
    "model_filename": "C:\\ai\\models\\Llama-3.3-70B-Instruct-Q4_K_M.gguf",
    "model_type": "llama 70B Q4_K - Medium",
    "model_size": 42512531712,
    "model_n_params": 70553706560,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 16,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "q4_0",
    "type_v": "q4_0",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": true,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": false,
    "use_direct_io": false,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 0,
    "n_depth": 0,
    "test_time": "2026-01-22T01:40:19Z",
    "avg_ns": 12886658920,
    "stddev_ns": 320669095,
    "avg_ts": 39.750680,
    "stddev_ts": 0.988104,
    "samples_ns": [ 12620520100, 13136086400, 13272041000, 12878096600, 12526550500 ],
    "samples_ts": [ 40.5689, 38.9766, 38.5773, 39.7574, 40.8732 ]
  },
  {
    "build_commit": "d1e355648",
    "build_number": 7783,
    "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ",
    "gpu_info": "AMD Radeon(TM) 8060S Graphics",
    "backends": "Vulkan",
    "model_filename": "C:\\ai\\models\\Llama-3.3-70B-Instruct-Q4_K_M.gguf",
    "model_type": "llama 70B Q4_K - Medium",
    "model_size": 42512531712,
    "model_n_params": 70553706560,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 16,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "q4_0",
    "type_v": "q4_0",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": true,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": false,
    "use_direct_io": false,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 2048,
    "n_gen": 0,
    "n_depth": 0,
    "test_time": "2026-01-22T01:41:37Z",
    "avg_ns": 57149162440,
    "stddev_ns": 1341278164,
    "avg_ts": 35.852080,
    "stddev_ts": 0.854159,
    "samples_ns": [ 56887543200, 55037201600, 57741798900, 57435404500, 58643864000 ],
    "samples_ts": [ 36.0009, 37.2112, 35.4682, 35.6574, 34.9227 ]
  },
  {
    "build_commit": "d1e355648",
    "build_number": 7783,
    "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ",
    "gpu_info": "AMD Radeon(TM) 8060S Graphics",
    "backends": "Vulkan",
    "model_filename": "C:\\ai\\models\\Llama-3.3-70B-Instruct-Q4_K_M.gguf",
    "model_type": "llama 70B Q4_K - Medium",
    "model_size": 42512531712,
    "model_n_params": 70553706560,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 16,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "q4_0",
    "type_v": "q4_0",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": true,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": false,
    "use_direct_io": false,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 0,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2026-01-22T01:47:19Z",
    "avg_ns": 25223292920,
    "stddev_ns": 17691761,
    "avg_ts": 5.074676,
    "stddev_ts": 0.003559,
    "samples_ns": [ 25240998000, 25202764200, 25209431500, 25221998000, 25241272900 ],
    "samples_ts": [ 5.07111, 5.07881, 5.07746, 5.07493, 5.07106 ]
  }
]
