[
  {
    "build_commit": "d1e355648",
    "build_number": 7783,
    "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ",
    "gpu_info": "AMD Radeon(TM) 8060S Graphics",
    "backends": "Vulkan",
    "model_filename": "C:\\ai\\models\\Llama-3.3-70B-Instruct-Q4_K_M.gguf",
    "model_type": "llama 70B Q4_K - Medium",
    "model_size": 42512531712,
    "model_n_params": 70553706560,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 16,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "q4_0",
    "type_v": "q4_0",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": true,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": false,
    "use_direct_io": false,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 0,
    "n_depth": 0,
    "test_time": "2026-01-24T19:42:23Z",
    "avg_ns": 12425336980,
    "stddev_ns": 3893785127,
    "avg_ts": 41.468028,
    "stddev_ts": 3.536478,
    "samples_ns": [ 11573527800, 11780670000, 14350808800, 12638263700, 11783414600 ],
    "samples_ts": [ 44.2389, 43.461, 35.6774, 40.5119, 43.4509 ]
  },
  {
    "build_commit": "d1e355648",
    "build_number": 7783,
    "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ",
    "gpu_info": "AMD Radeon(TM) 8060S Graphics",
    "backends": "Vulkan",
    "model_filename": "C:\\ai\\models\\Llama-3.3-70B-Instruct-Q4_K_M.gguf",
    "model_type": "llama 70B Q4_K - Medium",
    "model_size": 42512531712,
    "model_n_params": 70553706560,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 16,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "q4_0",
    "type_v": "q4_0",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": true,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": false,
    "use_direct_io": false,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 2048,
    "n_gen": 0,
    "n_depth": 0,
    "test_time": "2026-01-24T19:43:37Z",
    "avg_ns": 47101490060,
    "stddev_ns": 889075644,
    "avg_ts": 43.492791,
    "stddev_ts": 0.808867,
    "samples_ns": [ 46505500900, 46321335100, 48537530500, 47330357700, 46812726100 ],
    "samples_ts": [ 44.0378, 44.2129, 42.1942, 43.2703, 43.7488 ]
  },
  {
    "build_commit": "d1e355648",
    "build_number": 7783,
    "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ",
    "gpu_info": "AMD Radeon(TM) 8060S Graphics",
    "backends": "Vulkan",
    "model_filename": "C:\\ai\\models\\Llama-3.3-70B-Instruct-Q4_K_M.gguf",
    "model_type": "llama 70B Q4_K - Medium",
    "model_size": 42512531712,
    "model_n_params": 70553706560,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 16,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "q4_0",
    "type_v": "q4_0",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": true,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": false,
    "use_direct_io": false,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 0,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2026-01-24T19:48:24Z",
    "avg_ns": 25035327480,
    "stddev_ns": 20431182,
    "avg_ts": 5.112778,
    "stddev_ts": 0.004171,
    "samples_ns": [ 25014823600, 25066157400, 25023866800, 25026761100, 25045028500 ],
    "samples_ts": [ 5.11697, 5.10649, 5.11512, 5.11453, 5.11079 ]
  }
]
