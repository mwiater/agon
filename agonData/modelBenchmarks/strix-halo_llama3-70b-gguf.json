[
  {
    "build_commit": "d1e355648",
    "build_number": 7783,
    "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ",
    "gpu_info": "AMD Radeon(TM) 8060S Graphics",
    "backends": "Vulkan",
    "model_filename": "C:\\ai\\models\\Llama-3.3-70B-Instruct-Q4_K_M.gguf",
    "model_type": "llama 70B Q4_K - Medium",
    "model_size": 42512531712,
    "model_n_params": 70553706560,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 16,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "q4_0",
    "type_v": "q4_0",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": true,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": false,
    "use_direct_io": false,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 0,
    "n_depth": 0,
    "test_time": "2026-01-23T21:13:10Z",
    "avg_ns": 11829305040,
    "stddev_ns": 69101694,
    "avg_ts": 43.283526,
    "stddev_ts": 0.253787,
    "samples_ns": [ 11845386600, 11894950200, 11722185800, 11878983400, 11805019200 ],
    "samples_ts": [ 43.2236, 43.0435, 43.6779, 43.1013, 43.3714 ]
  },
  {
    "build_commit": "d1e355648",
    "build_number": 7783,
    "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ",
    "gpu_info": "AMD Radeon(TM) 8060S Graphics",
    "backends": "Vulkan",
    "model_filename": "C:\\ai\\models\\Llama-3.3-70B-Instruct-Q4_K_M.gguf",
    "model_type": "llama 70B Q4_K - Medium",
    "model_size": 42512531712,
    "model_n_params": 70553706560,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 16,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "q4_0",
    "type_v": "q4_0",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": true,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": false,
    "use_direct_io": false,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 2048,
    "n_gen": 0,
    "n_depth": 0,
    "test_time": "2026-01-23T21:14:22Z",
    "avg_ns": 49157072980,
    "stddev_ns": 3913194818,
    "avg_ts": 41.682497,
    "stddev_ts": 1.017497,
    "samples_ns": [ 48308222700, 49998650900, 48348169400, 48243051700, 50887270200 ],
    "samples_ts": [ 42.3944, 40.9611, 42.3594, 42.4517, 40.2458 ]
  },
  {
    "build_commit": "d1e355648",
    "build_number": 7783,
    "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ",
    "gpu_info": "AMD Radeon(TM) 8060S Graphics",
    "backends": "Vulkan",
    "model_filename": "C:\\ai\\models\\Llama-3.3-70B-Instruct-Q4_K_M.gguf",
    "model_type": "llama 70B Q4_K - Medium",
    "model_size": 42512531712,
    "model_n_params": 70553706560,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 16,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "q4_0",
    "type_v": "q4_0",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": true,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": false,
    "use_direct_io": false,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 0,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2026-01-23T21:19:18Z",
    "avg_ns": 25144452220,
    "stddev_ns": 17600479,
    "avg_ts": 5.090588,
    "stddev_ts": 0.003565,
    "samples_ns": [ 25163516100, 25137281400, 25154931200, 25148500900, 25118031500 ],
    "samples_ts": [ 5.08673, 5.09204, 5.08847, 5.08977, 5.09594 ]
  }
]
