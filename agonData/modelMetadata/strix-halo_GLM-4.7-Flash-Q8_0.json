{
  "type": "llama.cpp",
  "name": "GLM-4.7-Flash-Q8_0",
  "endpoint": "http://192.168.0.239:9998",
  "gpu": "strix-halo",
  "metadata": {
    "bos_token": "[gMASK]",
    "build_info": "b7783-d1e355648",
    "chat_template": "[gMASK]\u003csop\u003e\n{%- if tools -%}\n\u003c|system|\u003e\n# Tools\n\nYou may call one or more functions to assist with the user query.\n\nYou are provided with function signatures within \u003ctools\u003e\u003c/tools\u003e XML tags:\n\u003ctools\u003e\n{% for tool in tools %}\n{{ tool | tojson(ensure_ascii=False) }}\n{% endfor %}\n\u003c/tools\u003e\n\nFor each function call, output the function name and arguments within the following XML format:\n\u003ctool_call\u003e{function-name}\u003carg_key\u003e{arg-key-1}\u003c/arg_key\u003e\u003carg_value\u003e{arg-value-1}\u003c/arg_value\u003e\u003carg_key\u003e{arg-key-2}\u003c/arg_key\u003e\u003carg_value\u003e{arg-value-2}\u003c/arg_value\u003e...\u003c/tool_call\u003e{%- endif -%}\n{%- macro visible_text(content) -%}\n    {%- if content is string -%}\n        {{- content }}\n    {%- elif content is iterable and content is not mapping -%}\n        {%- for item in content -%}\n            {%- if item is mapping and item.type == 'text' -%}\n                {{- item.text }}\n            {%- elif item is string -%}\n                {{- item }}\n            {%- endif -%}\n        {%- endfor -%}\n    {%- else -%}\n        {{- content }}\n    {%- endif -%}\n{%- endmacro -%}\n{%- set ns = namespace(last_user_index=-1) %}\n{%- for m in messages %}\n    {%- if m.role == 'user' %}\n        {% set ns.last_user_index = loop.index0 -%}\n    {%- endif %}\n{%- endfor %}\n{% for m in messages %}\n{%- if m.role == 'user' -%}\u003c|user|\u003e{{ visible_text(m.content) }}\n{%- elif m.role == 'assistant' -%}\n\u003c|assistant|\u003e\n{%- set reasoning_content = '' %}\n{%- set content = visible_text(m.content) %}\n{%- if m.reasoning_content is string %}\n    {%- set reasoning_content = m.reasoning_content %}\n{%- else %}\n    {%- if '\u003c/think\u003e' in content %}\n        {%- set reasoning_content = content.split('\u003c/think\u003e')[0].rstrip('\\n').split('\u003cthink\u003e')[-1].lstrip('\\n') %}\n        {%- set content = content.split('\u003c/think\u003e')[-1].lstrip('\\n') %}\n    {%- endif %}\n{%- endif %}\n{%- if ((clear_thinking is defined and not clear_thinking) or loop.index0 \u003e ns.last_user_index) and reasoning_content -%}\n{{ '\u003cthink\u003e' + reasoning_content.strip() +  '\u003c/think\u003e'}}\n{%- else -%}\n{{ '\u003c/think\u003e' }}\n{%- endif -%}\n{%- if content.strip() -%}\n{{ content.strip() }}\n{%- endif -%}\n{% if m.tool_calls %}\n{% for tc in m.tool_calls %}\n{%- if tc.function %}\n    {%- set tc = tc.function %}\n{%- endif %}\n{{- '\u003ctool_call\u003e' + tc.name -}}\n{% set _args = tc.arguments %}{% for k, v in _args.items() %}\u003carg_key\u003e{{ k }}\u003c/arg_key\u003e\u003carg_value\u003e{{ v | tojson(ensure_ascii=False) if v is not string else v }}\u003c/arg_value\u003e{% endfor %}\u003c/tool_call\u003e{% endfor %}\n{% endif %}\n{%- elif m.role == 'tool' -%}\n{%- if m.content is string -%}\n{%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n    {{- '\u003c|observation|\u003e' }}\n{%- endif %}\n{{- '\u003ctool_response\u003e' }}\n{{- m.content }}\n{{- '\u003c/tool_response\u003e' }}\n{%- else -%}\n\u003c|observation|\u003e{% for tr in m.content %}\n\u003ctool_response\u003e{{ tr.output if tr.output is defined else tr }}\u003c/tool_response\u003e{% endfor -%}\n{% endif -%}\n{%- elif m.role == 'system' -%}\n\u003c|system|\u003e{{ visible_text(m.content) }}\n{%- endif -%}\n{%- endfor -%}\n{%- if add_generation_prompt -%}\n    \u003c|assistant|\u003e{{- '\u003c/think\u003e' if (enable_thinking is defined and not enable_thinking) else '\u003cthink\u003e' -}}\n{%- endif -%}",
    "default_generation_settings": {
      "n_ctx": 202752,
      "params": {
        "backend_sampling": false,
        "chat_format": "Content-only",
        "dry_allowed_length": 2,
        "dry_base": 1.75,
        "dry_multiplier": 0,
        "dry_penalty_last_n": -1,
        "dynatemp_exponent": 1,
        "dynatemp_range": 0,
        "frequency_penalty": 0,
        "ignore_eos": false,
        "lora": [],
        "max_tokens": -1,
        "min_keep": 0,
        "min_p": 0.05000000074505806,
        "mirostat": 0,
        "mirostat_eta": 0.10000000149011612,
        "mirostat_tau": 5,
        "n_discard": 0,
        "n_keep": 0,
        "n_predict": -1,
        "n_probs": 0,
        "post_sampling_probs": false,
        "presence_penalty": 0,
        "reasoning_format": "none",
        "reasoning_in_content": false,
        "repeat_last_n": 64,
        "repeat_penalty": 1,
        "samplers": [
          "penalties",
          "dry",
          "top_n_sigma",
          "top_k",
          "typ_p",
          "top_p",
          "min_p",
          "xtc",
          "temperature"
        ],
        "seed": 4294967295,
        "speculative.n_max": 16,
        "speculative.n_min": 0,
        "speculative.p_min": 0.75,
        "stream": true,
        "temperature": 0.800000011920929,
        "thinking_forced_open": false,
        "timings_per_token": false,
        "top_k": 40,
        "top_n_sigma": -1,
        "top_p": 0.949999988079071,
        "typical_p": 1,
        "xtc_probability": 0,
        "xtc_threshold": 0.10000000149011612
      }
    },
    "endpoint_metrics": true,
    "endpoint_props": false,
    "endpoint_slots": true,
    "eos_token": "\u003c|endoftext|\u003e",
    "is_sleeping": false,
    "modalities": {
      "audio": false,
      "vision": false
    },
    "model_alias": "GLM-4.7-Flash-Q8_0",
    "model_path": "C:\\ai\\models\\GLM-4.7-Flash-Q8_0.gguf",
    "total_slots": 4,
    "webui": false,
    "webui_settings": {}
  }
}