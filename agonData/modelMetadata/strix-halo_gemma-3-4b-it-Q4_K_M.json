{
  "type": "llama.cpp",
  "name": "gemma-3-4b-it-Q4_K_M",
  "endpoint": "https://strix.ngrok.app",
  "gpu": "strix-halo",
  "metadata": {
    "bos_token": "\u003cbos\u003e",
    "build_info": "b7783-d1e355648",
    "chat_template": "{{ bos_token }}\n{%- if messages[0]['role'] == 'system' -%}\n    {%- if messages[0]['content'] is string -%}\n        {%- set first_user_prefix = messages[0]['content'] + '\n\n' -%}\n    {%- else -%}\n        {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\n\n' -%}\n    {%- endif -%}\n    {%- set loop_messages = messages[1:] -%}\n{%- else -%}\n    {%- set first_user_prefix = \"\" -%}\n    {%- set loop_messages = messages -%}\n{%- endif -%}\n{%- for message in loop_messages -%}\n    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\n        {{ raise_exception(\"Conversation roles must alternate user/assistant/user/assistant/...\") }}\n    {%- endif -%}\n    {%- if (message['role'] == 'assistant') -%}\n        {%- set role = \"model\" -%}\n    {%- else -%}\n        {%- set role = message['role'] -%}\n    {%- endif -%}\n    {{ '\u003cstart_of_turn\u003e' + role + '\n' + (first_user_prefix if loop.first else \"\") }}\n    {%- if message['content'] is string -%}\n        {{ message['content'] | trim }}\n    {%- elif message['content'] is iterable -%}\n        {%- for item in message['content'] -%}\n            {%- if item['type'] == 'image' -%}\n                {{ '\u003cstart_of_image\u003e' }}\n            {%- elif item['type'] == 'text' -%}\n                {{ item['text'] | trim }}\n            {%- endif -%}\n        {%- endfor -%}\n    {%- else -%}\n        {{ raise_exception(\"Invalid content type\") }}\n    {%- endif -%}\n    {{ '\u003cend_of_turn\u003e\n' }}\n{%- endfor -%}\n{%- if add_generation_prompt -%}\n    {{'\u003cstart_of_turn\u003emodel\n'}}\n{%- endif -%}",
    "default_generation_settings": {
      "n_ctx": 16384,
      "params": {
        "backend_sampling": false,
        "chat_format": "Content-only",
        "dry_allowed_length": 2,
        "dry_base": 1.75,
        "dry_multiplier": 0,
        "dry_penalty_last_n": -1,
        "dynatemp_exponent": 1,
        "dynatemp_range": 0,
        "frequency_penalty": 0,
        "ignore_eos": false,
        "lora": [],
        "max_tokens": -1,
        "min_keep": 0,
        "min_p": 0.05000000074505806,
        "mirostat": 0,
        "mirostat_eta": 0.10000000149011612,
        "mirostat_tau": 5,
        "n_discard": 0,
        "n_keep": 0,
        "n_predict": -1,
        "n_probs": 0,
        "post_sampling_probs": false,
        "presence_penalty": 0,
        "reasoning_format": "none",
        "reasoning_in_content": false,
        "repeat_last_n": 64,
        "repeat_penalty": 1,
        "samplers": [
          "penalties",
          "dry",
          "top_n_sigma",
          "top_k",
          "typ_p",
          "top_p",
          "min_p",
          "xtc",
          "temperature"
        ],
        "seed": 4294967295,
        "speculative.n_max": 16,
        "speculative.n_min": 0,
        "speculative.p_min": 0.75,
        "stream": true,
        "temperature": 0.800000011920929,
        "thinking_forced_open": false,
        "timings_per_token": false,
        "top_k": 40,
        "top_n_sigma": -1,
        "top_p": 0.949999988079071,
        "typical_p": 1,
        "xtc_probability": 0,
        "xtc_threshold": 0.10000000149011612
      }
    },
    "endpoint_metrics": false,
    "endpoint_props": false,
    "endpoint_slots": true,
    "eos_token": "\u003ceos\u003e",
    "is_sleeping": false,
    "modalities": {
      "audio": false,
      "vision": false
    },
    "model_alias": "gemma-3-4b-it-Q4_K_M",
    "model_path": "C:\\ai\\models\\gemma-3-4b-it-Q4_K_M.gguf",
    "total_slots": 4,
    "webui": true,
    "webui_settings": {}
  }
}