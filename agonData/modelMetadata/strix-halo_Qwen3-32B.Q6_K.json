{
  "type": "llama.cpp",
  "name": "Qwen3-32B.Q6_K",
  "endpoint": "https://strix.ngrok.app",
  "gpu": "strix-halo",
  "metadata": {
    "bos_token": "\u003c|endoftext|\u003e",
    "build_info": "b7783-d1e355648",
    "chat_template": "{%- if tools %}\n    {{- '\u003c|im_start|\u003esystem\\n' }}\n    {%- if messages[0].role == 'system' %}\n        {{- messages[0].content + '\\n\\n' }}\n    {%- endif %}\n    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within \u003ctools\u003e\u003c/tools\u003e XML tags:\\n\u003ctools\u003e\" }}\n    {%- for tool in tools %}\n        {{- \"\\n\" }}\n        {{- tool | tojson }}\n    {%- endfor %}\n    {{- \"\\n\u003c/tools\u003e\\n\\nFor each function call, return a json object with function name and arguments within \u003ctool_call\u003e\u003c/tool_call\u003e XML tags:\\n\u003ctool_call\u003e\\n{\\\"name\\\": \u003cfunction-name\u003e, \\\"arguments\\\": \u003cargs-json-object\u003e}\\n\u003c/tool_call\u003e\u003c|im_end|\u003e\\n\" }}\n{%- else %}\n    {%- if messages[0].role == 'system' %}\n        {{- '\u003c|im_start|\u003esystem\\n' + messages[0].content + '\u003c|im_end|\u003e\\n' }}\n    {%- endif %}\n{%- endif %}\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n{%- for message in messages[::-1] %}\n    {%- set index = (messages|length - 1) - loop.index0 %}\n    {%- if ns.multi_step_tool and message.role == \"user\" and not(message.content.startswith('\u003ctool_response\u003e') and message.content.endswith('\u003c/tool_response\u003e')) %}\n        {%- set ns.multi_step_tool = false %}\n        {%- set ns.last_query_index = index %}\n    {%- endif %}\n{%- endfor %}\n{%- for message in messages %}\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n        {{- '\u003c|im_start|\u003e' + message.role + '\\n' + message.content + '\u003c|im_end|\u003e' + '\\n' }}\n    {%- elif message.role == \"assistant\" %}\n        {%- set content = message.content %}\n        {%- set reasoning_content = '' %}\n        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n            {%- set reasoning_content = message.reasoning_content %}\n        {%- else %}\n            {%- if '\u003c/think\u003e' in message.content %}\n                {%- set content = message.content.split('\u003c/think\u003e')[-1].lstrip('\\n') %}\n                {%- set reasoning_content = message.content.split('\u003c/think\u003e')[0].rstrip('\\n').split('\u003cthink\u003e')[-1].lstrip('\\n') %}\n            {%- endif %}\n        {%- endif %}\n        {%- if loop.index0 \u003e ns.last_query_index %}\n            {%- if loop.last or (not loop.last and reasoning_content) %}\n                {{- '\u003c|im_start|\u003e' + message.role + '\\n\u003cthink\u003e\\n' + reasoning_content.strip('\\n') + '\\n\u003c/think\u003e\\n\\n' + content.lstrip('\\n') }}\n            {%- else %}\n                {{- '\u003c|im_start|\u003e' + message.role + '\\n' + content }}\n            {%- endif %}\n        {%- else %}\n            {{- '\u003c|im_start|\u003e' + message.role + '\\n' + content }}\n        {%- endif %}\n        {%- if message.tool_calls %}\n            {%- for tool_call in message.tool_calls %}\n                {%- if (loop.first and content) or (not loop.first) %}\n                    {{- '\\n' }}\n                {%- endif %}\n                {%- if tool_call.function %}\n                    {%- set tool_call = tool_call.function %}\n                {%- endif %}\n                {{- '\u003ctool_call\u003e\\n{\"name\": \"' }}\n                {{- tool_call.name }}\n                {{- '\", \"arguments\": ' }}\n                {%- if tool_call.arguments is string %}\n                    {{- tool_call.arguments }}\n                {%- else %}\n                    {{- tool_call.arguments | tojson }}\n                {%- endif %}\n                {{- '}\\n\u003c/tool_call\u003e' }}\n            {%- endfor %}\n        {%- endif %}\n        {{- '\u003c|im_end|\u003e\\n' }}\n    {%- elif message.role == \"tool\" %}\n        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n            {{- '\u003c|im_start|\u003euser' }}\n        {%- endif %}\n        {{- '\\n\u003ctool_response\u003e\\n' }}\n        {{- message.content }}\n        {{- '\\n\u003c/tool_response\u003e' }}\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n            {{- '\u003c|im_end|\u003e\\n' }}\n        {%- endif %}\n    {%- endif %}\n{%- endfor %}\n{%- if add_generation_prompt %}\n    {{- '\u003c|im_start|\u003eassistant\\n' }}\n    {%- if enable_thinking is defined and enable_thinking is false %}\n        {{- '\u003cthink\u003e\\n\\n\u003c/think\u003e\\n\\n' }}\n    {%- endif %}\n{%- endif %}",
    "default_generation_settings": {
      "n_ctx": 16384,
      "params": {
        "backend_sampling": false,
        "chat_format": "Content-only",
        "dry_allowed_length": 2,
        "dry_base": 1.75,
        "dry_multiplier": 0,
        "dry_penalty_last_n": -1,
        "dynatemp_exponent": 1,
        "dynatemp_range": 0,
        "frequency_penalty": 0,
        "ignore_eos": false,
        "lora": [],
        "max_tokens": -1,
        "min_keep": 0,
        "min_p": 0.05000000074505806,
        "mirostat": 0,
        "mirostat_eta": 0.10000000149011612,
        "mirostat_tau": 5,
        "n_discard": 0,
        "n_keep": 0,
        "n_predict": -1,
        "n_probs": 0,
        "post_sampling_probs": false,
        "presence_penalty": 0,
        "reasoning_format": "none",
        "reasoning_in_content": false,
        "repeat_last_n": 64,
        "repeat_penalty": 1,
        "samplers": [
          "penalties",
          "dry",
          "top_n_sigma",
          "top_k",
          "typ_p",
          "top_p",
          "min_p",
          "xtc",
          "temperature"
        ],
        "seed": 4294967295,
        "speculative.n_max": 16,
        "speculative.n_min": 0,
        "speculative.p_min": 0.75,
        "stream": true,
        "temperature": 0.800000011920929,
        "thinking_forced_open": false,
        "timings_per_token": false,
        "top_k": 40,
        "top_n_sigma": -1,
        "top_p": 0.949999988079071,
        "typical_p": 1,
        "xtc_probability": 0,
        "xtc_threshold": 0.10000000149011612
      }
    },
    "endpoint_metrics": false,
    "endpoint_props": false,
    "endpoint_slots": true,
    "eos_token": "\u003c|im_end|\u003e",
    "is_sleeping": false,
    "modalities": {
      "audio": false,
      "vision": false
    },
    "model_alias": "Qwen3-32B.Q6_K",
    "model_path": "C:\\ai\\models\\Qwen3-32B.Q6_K.gguf",
    "total_slots": 4,
    "webui": true,
    "webui_settings": {}
  }
}