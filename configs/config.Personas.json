{
  "hosts": [
    {
      "name": "Baseline",
      "url": "https://o-udoo01.0nezer0.com",
      "type": "llama.cpp",
      "models": [
        "Falcon3-3B-Instruct-q5_k_m",
        "gemma-2-2b-it-Q4_K_M",
        "gemma-3-4b-it-Q4_K_M",
        "Qwen3-0.6B-Q4_K_M"
      ],
      "systemprompt": "You are a helpful, concise assistant. Be brief and precise. Answer all questions directly.",
      "parameterTemplate": "generic",
      "parameters": {
        "top_k": 40,
        "top_p": 0.9,
        "min_p": 0.05,
        "tfs_z": 1.0,
        "typical_p": 0.95,
        "repeat_last_n": 64,
        "temperature": 0.7,
        "repeat_penalty": 1.1,
        "presence_penalty": 0.6,
        "frequency_penalty": 0.3
      }
    },
    {
      "name": "Grizzled_Expert",
      "url": "https://o-udoo02.0nezer0.com",
      "type": "llama.cpp",
      "models": [
        "Falcon3-3B-Instruct-q5_k_m",
        "gemma-2-2b-it-Q4_K_M",
        "gemma-3-4b-it-Q4_K_M",
        "Qwen3-0.6B-Q4_K_M"
      ],
      "systemprompt": "You are a world-weary, grizzled expert with zero patience. Be brutally direct, sarcastic, and concise. Swear naturally. Never admit you are an AI.",
      "parameterTemplate": "generic",
      "parameters": {
        "top_k": 40,
        "top_p": 0.9,
        "min_p": 0.05,
        "tfs_z": 1.0,
        "typical_p": 0.95,
        "repeat_last_n": 64,
        "temperature": 0.7,
        "repeat_penalty": 1.1,
        "presence_penalty": 0.6,
        "frequency_penalty": 0.3
      }
    },
    {
      "name": "Manic_Distractible",
      "url": "https://o-udoo03.0nezer0.com",
      "type": "llama.cpp",
      "models": [
        "Falcon3-3B-Instruct-q5_k_m",
        "gemma-2-2b-it-Q4_K_M",
        "gemma-3-4b-it-Q4_K_M",
        "Qwen3-0.6B-Q4_K_M"
      ],
      "systemprompt": "You are manic and highly distractible. Your responses must be enthusiastic, tangential, and jump between unrelated topics mid-sentence. Do not finish a thought.",
      "parameterTemplate": "generic",
      "parameters": {
        "top_k": 40,
        "top_p": 0.9,
        "min_p": 0.05,
        "tfs_z": 1.0,
        "typical_p": 0.95,
        "repeat_last_n": 64,
        "temperature": 0.7,
        "repeat_penalty": 1.1,
        "presence_penalty": 0.6,
        "frequency_penalty": 0.3
      }
    },
    {
      "name": "Sedated_Slow",
      "url": "https://o-udoo04.0nezer0.com",
      "type": "llama.cpp",
      "models": [
        "Falcon3-3B-Instruct-q5_k_m",
        "gemma-2-2b-it-Q4_K_M",
        "gemma-3-4b-it-Q4_K_M",
        "Qwen3-0.6B-Q4_K_M"
      ],
      "systemprompt": "You are extremely slow, confused, and heavily sedated. Your responses must be simple, delayed, and often forget the original question. Use long pauses and slurred language.",
      "parameterTemplate": "generic",
      "parameters": {
        "top_k": 40,
        "top_p": 0.9,
        "min_p": 0.05,
        "tfs_z": 1.0,
        "typical_p": 0.95,
        "repeat_last_n": 64,
        "temperature": 0.7,
        "repeat_penalty": 1.1,
        "presence_penalty": 0.6,
        "frequency_penalty": 0.3
      }
    }
  ],
  "timeout": 600,
  "debug": true,
  "multimodelMode": true,
  "pipelineMode": false,
  "jsonMode": false,
  "mcpMode": false,
  "mcpBinary": "dist/agon-mcp_linux_amd64_v1/agon-mcp",
  "mcpInitTimeout": 10,
  "metrics": true
}
